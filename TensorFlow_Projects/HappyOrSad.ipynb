{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HappyOrSad.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJm3Wg085vxp"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import zipfile\n",
        "from os import path, getcwd, chdir\n",
        "from google.colab import files\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "path = f\"{getcwd()}/happy-or-sad.zip\"\n",
        "\n",
        "zip_ref = zipfile.ZipFile(path, 'r')\n",
        "zip_ref.extractall(\"tmp/h-or-s\")\n",
        "zip_ref.close()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8Bf9Y_QvnRG"
      },
      "source": [
        "\n",
        "- In this module, we have used Image Data Generator which will automatically label the data according to the name of the folders.\n",
        "\n",
        "- The model.fit will change into model.fit_generator. We can define the same thing for the validation and test sets.\n",
        "\n",
        "- The optimizer that is used here is RMSprop which is better than sgd or adam since the learning rate could be determined in it.\n",
        "\n",
        "- Since this problem is a binary classification problem the last layer MUST have 1 unit (close to 0 or 1) and the activation function should be set to 'sigmoid' instead of 'softmax'. The loss function is also changed into 'binary cross entropy' instead of 'categorical cross entropy'\n",
        "- The batch size plays an important role here since if we change it the accuracy might change a lot."
        "- We use convolution layers to find the features in the image, wherever they are"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkvFPG0NmaLB"
      },
      "source": [
        "def train_happy_sad_model():\n",
        "    DESIRED_ACCURACY = 0.999\n",
        "\n",
        "    class myCallback(tf.keras.callbacks.Callback):\n",
        "         def on_epoch_end(self,epoch,logs={}):\n",
        "                if(logs.get('accuracy')>DESIRED_ACCURACY):\n",
        "                    print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "                    self.model.stop_training = True\n",
        "\n",
        "    callbacks = myCallback()\n",
        "\n",
        "    model = tf.keras.models.Sequential([tf.keras.layers.Conv2D(16,(3,3),activation = 'relu', input_shape=(150,150,3)),\n",
        "                                      tf.keras.layers.MaxPooling2D((2,2)),\n",
        "                                      tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n",
        "                                      tf.keras.layers.MaxPooling2D((2,2)),\n",
        "                                      tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n",
        "                                      tf.keras.layers.MaxPooling2D((2,2)),\n",
        "                                      tf.keras.layers.Flatten(),\n",
        "                                      tf.keras.layers.Dense(units=512, activation = 'relu'),\n",
        "                                      tf.keras.layers.Dense(units=1,activation = 'sigmoid')\n",
        "    ])\n",
        "  \n",
        "    model.compile(optimizer = RMSprop(lr=0.01), loss='binary_crossentropy',metrics=['accuracy'])\n",
        "    tr_datagen = ImageDataGenerator(rescale=1/255)\n",
        "    tr_generator = tr_datagen.flow_from_directory('./tmp/h-or-s/happy-or-sad',\n",
        "                                                target_size = (150,150),\n",
        "                                                batch_size = 10,\n",
        "                                                class_mode = 'binary')\n",
        "  \n",
        "    history = model.fit_generator(tr_generator, steps_per_epoch = 8, epochs = 100, verbose = 1, callbacks = [callbacks])\n",
        "    return history.history['accuracy'][-1]    \n",
        " "
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saWAWNoiq9pw",
        "outputId": "18d555a3-5d68-4f16-ec1f-2d6a3b188e89"
      },
      "source": [
        "train_happy_sad_model()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 79 images belonging to 2 classes.\n",
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 3s 214ms/step - loss: 300.4715 - accuracy: 0.4100\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 2s 215ms/step - loss: 0.8678 - accuracy: 0.5171\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 2s 215ms/step - loss: 0.6622 - accuracy: 0.6617\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 2s 219ms/step - loss: 0.4838 - accuracy: 0.8291\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 2s 216ms/step - loss: 0.3468 - accuracy: 0.8789\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 2s 216ms/step - loss: 0.2024 - accuracy: 0.9126\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 2s 224ms/step - loss: 0.1904 - accuracy: 0.9573\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 2s 215ms/step - loss: 0.3127 - accuracy: 0.8811\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 2s 214ms/step - loss: 0.2959 - accuracy: 0.8771\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 2s 218ms/step - loss: 0.1149 - accuracy: 0.9602\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 2s 213ms/step - loss: 0.2322 - accuracy: 0.9287\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 2s 217ms/step - loss: 5.6358 - accuracy: 0.8895\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 2s 212ms/step - loss: 0.1156 - accuracy: 0.9795\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 2s 212ms/step - loss: 0.2759 - accuracy: 0.9654\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 2s 211ms/step - loss: 0.2332 - accuracy: 0.9200\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 2s 209ms/step - loss: 0.0351 - accuracy: 1.0000\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    }
  ]
}
